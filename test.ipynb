{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2439d434-bd57-493a-a089-1b96f19ea722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "# model_dtype = torch.bfloat16 \n",
    "model_dtype = torch.float32\n",
    "\n",
    "model = nn.Linear(10, 5)\n",
    "model.to(model_dtype)\n",
    "\n",
    "# Toy case: \n",
    "# - multiplication operation (dimension pair multiply)\n",
    "N = 50\n",
    "input = torch.randn((N, 10)).to(model_dtype)\n",
    "output = input[:,::2] * input[:,1::2].to(model_dtype)\n",
    "\n",
    "def criterion(pred, target): \n",
    "    l2_loss = torch.norm(pred - output, p=2, dim=1)\n",
    "    return l2_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5d81d14-76df-4f36-91ec-0b41002066e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from yao import YAO\n",
    "from temp_yao import YAO\n",
    "\n",
    "# yao optimizer\n",
    "yao_optimizer = YAO(params=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ad1d011-5329-467c-80fe-af5bebc71c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Global Step ::\n",
      "Train iter 0/100 - loss 2.2631921768188477\n",
      "Train iter 1/100 - loss 2.262282371520996\n",
      "Train iter 2/100 - loss 2.261791467666626\n",
      "Train iter 3/100 - loss 2.2610867023468018\n",
      "Train iter 4/100 - loss 2.260451555252075\n",
      "Train iter 5/100 - loss 2.2594103813171387\n",
      "Train iter 6/100 - loss 2.2584586143493652\n",
      "Train iter 7/100 - loss 2.257549285888672\n",
      "Train iter 8/100 - loss 2.256727695465088\n",
      "Train iter 9/100 - loss 2.2558224201202393\n",
      ":: Global Step ::\n",
      "Train iter 10/100 - loss 2.2548744678497314\n",
      "Train iter 11/100 - loss 2.253951072692871\n",
      "Train iter 12/100 - loss 2.253005027770996\n",
      "Train iter 13/100 - loss 2.2522101402282715\n",
      "Train iter 14/100 - loss 2.251286268234253\n",
      "Train iter 15/100 - loss 2.250624418258667\n",
      "Train iter 16/100 - loss 2.249948024749756\n",
      "Train iter 17/100 - loss 2.249108076095581\n",
      "Train iter 18/100 - loss 2.2481565475463867\n",
      "Train iter 19/100 - loss 2.24727725982666\n",
      ":: Global Step ::\n",
      "Train iter 20/100 - loss 2.2463643550872803\n",
      "Train iter 21/100 - loss 2.2454776763916016\n",
      "Train iter 22/100 - loss 2.244576930999756\n",
      "Train iter 23/100 - loss 2.243734359741211\n",
      "Train iter 24/100 - loss 2.2430577278137207\n",
      "Train iter 25/100 - loss 2.242283582687378\n",
      "Train iter 26/100 - loss 2.241503953933716\n",
      "Train iter 27/100 - loss 2.2406816482543945\n",
      "Train iter 28/100 - loss 2.239800214767456\n",
      "Train iter 29/100 - loss 2.2388601303100586\n",
      ":: Global Step ::\n",
      "Train iter 30/100 - loss 2.2379117012023926\n",
      "Train iter 31/100 - loss 2.236956834793091\n",
      "Train iter 32/100 - loss 2.23602032661438\n",
      "Train iter 33/100 - loss 2.2351114749908447\n",
      "Train iter 34/100 - loss 2.234184503555298\n",
      "Train iter 35/100 - loss 2.2332286834716797\n",
      "Train iter 36/100 - loss 2.2324271202087402\n",
      "Train iter 37/100 - loss 2.2317512035369873\n",
      "Train iter 38/100 - loss 2.2310683727264404\n",
      "Train iter 39/100 - loss 2.2303574085235596\n",
      ":: Global Step ::\n",
      "Train iter 40/100 - loss 2.229799270629883\n",
      "Train iter 41/100 - loss 2.229058027267456\n",
      "Train iter 42/100 - loss 2.228306531906128\n",
      "Train iter 43/100 - loss 2.2275664806365967\n",
      "Train iter 44/100 - loss 2.2268052101135254\n",
      "Train iter 45/100 - loss 2.226020097732544\n",
      "Train iter 46/100 - loss 2.225414991378784\n",
      "Train iter 47/100 - loss 2.224794864654541\n",
      "Train iter 48/100 - loss 2.224097967147827\n",
      "Train iter 49/100 - loss 2.223360538482666\n",
      ":: Global Step ::\n",
      "Train iter 50/100 - loss 2.2226908206939697\n",
      "Train iter 51/100 - loss 2.2220938205718994\n",
      "Train iter 52/100 - loss 2.221482038497925\n",
      "Train iter 53/100 - loss 2.220872402191162\n",
      "Train iter 54/100 - loss 2.2202954292297363\n",
      "Train iter 55/100 - loss 2.2196991443634033\n",
      "Train iter 56/100 - loss 2.2190821170806885\n",
      "Train iter 57/100 - loss 2.218435525894165\n",
      "Train iter 58/100 - loss 2.2178754806518555\n",
      "Train iter 59/100 - loss 2.2172818183898926\n",
      ":: Global Step ::\n",
      "Train iter 60/100 - loss 2.216719627380371\n",
      "Train iter 61/100 - loss 2.216074228286743\n",
      "Train iter 62/100 - loss 2.215503454208374\n",
      "Train iter 63/100 - loss 2.2149510383605957\n",
      "Train iter 64/100 - loss 2.214322566986084\n",
      "Train iter 65/100 - loss 2.2136690616607666\n",
      "Train iter 66/100 - loss 2.2129857540130615\n",
      "Train iter 67/100 - loss 2.2122886180877686\n",
      "Train iter 68/100 - loss 2.2116732597351074\n",
      "Train iter 69/100 - loss 2.2110257148742676\n",
      ":: Global Step ::\n",
      "Train iter 70/100 - loss 2.2103419303894043\n",
      "Train iter 71/100 - loss 2.2096524238586426\n",
      "Train iter 72/100 - loss 2.20900821685791\n",
      "Train iter 73/100 - loss 2.2084405422210693\n",
      "Train iter 74/100 - loss 2.207854986190796\n",
      "Train iter 75/100 - loss 2.207231044769287\n",
      "Train iter 76/100 - loss 2.2066152095794678\n",
      "Train iter 77/100 - loss 2.2059924602508545\n",
      "Train iter 78/100 - loss 2.2054567337036133\n",
      "Train iter 79/100 - loss 2.2047417163848877\n",
      ":: Global Step ::\n",
      "Train iter 80/100 - loss 2.2042036056518555\n",
      "Train iter 81/100 - loss 2.203463554382324\n",
      "Train iter 82/100 - loss 2.2028517723083496\n",
      "Train iter 83/100 - loss 2.202176332473755\n",
      "Train iter 84/100 - loss 2.2015328407287598\n",
      "Train iter 85/100 - loss 2.200922966003418\n",
      "Train iter 86/100 - loss 2.2001099586486816\n",
      "Train iter 87/100 - loss 2.199497699737549\n",
      "Train iter 88/100 - loss 2.198697090148926\n",
      "Train iter 89/100 - loss 2.1979475021362305\n",
      ":: Global Step ::\n",
      "Train iter 90/100 - loss 2.1972408294677734\n",
      "Train iter 91/100 - loss 2.196497917175293\n",
      "Train iter 92/100 - loss 2.195817708969116\n",
      "Train iter 93/100 - loss 2.1951184272766113\n",
      "Train iter 94/100 - loss 2.1944010257720947\n",
      "Train iter 95/100 - loss 2.193662643432617\n",
      "Train iter 96/100 - loss 2.1929969787597656\n",
      "Train iter 97/100 - loss 2.1923065185546875\n",
      "Train iter 98/100 - loss 2.191652774810791\n",
      "Train iter 99/100 - loss 2.190999984741211\n"
     ]
    }
   ],
   "source": [
    "# loop \n",
    "epochs = 100 \n",
    "\n",
    "for epoch in range(epochs): \n",
    "    pred = model(input)\n",
    "    loss = criterion(pred, output)\n",
    "\n",
    "    yao_optimizer.zero_grad() \n",
    "    loss.backward() \n",
    "    yao_optimizer.step(loss)\n",
    "    print(f\"Train iter {epoch}/{epochs} - loss {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af25ca21-8669-4213-be40-681581fe1300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5268ae1d-3a86-4d7f-9162-555f44bbdeab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab3c363-63f3-4941-90dc-552431a5bda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdd9f057-09d9-47f5-a3a9-ac54816527d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update max_loss and compute new rank\n",
    "self = yao_optimizer \n",
    "current_loss = loss.item() \n",
    "\n",
    "if self.max_loss is None:\n",
    "    self.max_loss = current_loss\n",
    "else:\n",
    "    self.max_loss = max(self.max_loss, current_loss)\n",
    "\n",
    "for group in self.param_groups:\n",
    "    for p in group[\"params\"]:\n",
    "        if not self.state[p][\"use_arg\"]:\n",
    "            continue  # Skip non-low-rank params\n",
    "\n",
    "        state = self.state[p]\n",
    "        if \"moment1_u\" not in state:\n",
    "            continue  # Not initialized yet\n",
    "\n",
    "        # Adaptive rank for each parameter\n",
    "        new_rank = calculate_rank(current_loss, self.max_loss, max_rank=min(p.shape))\n",
    "\n",
    "        # Get current rank and buffers\n",
    "        current_rank = state[\"moment1_u\"].shape[1]\n",
    "        if new_rank == current_rank:\n",
    "            continue  # No change needed\n",
    "\n",
    "        # Project momentum buffers to new rank\n",
    "        state[\"moment1_u\"] = self._adjust_rank(state[\"moment1_u\"], new_rank)\n",
    "        state[\"moment1_v\"] = self._adjust_rank(state[\"moment1_v\"], new_rank)\n",
    "        state[\"moment1_s\"] = self._adjust_rank(state[\"moment1_s\"], new_rank)\n",
    "        state[\"moment2_s\"] = self._adjust_rank(state[\"moment2_s\"], new_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f569b7e-0032-48e7-a54e-c232a85de1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: 2.1349761486053467 | Max loss: 2.1414403915405273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 99])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_rank # new rank is 99 --> wrong ... \n",
    "print(f\"Current loss: {current_loss} | Max loss: {self.max_loss}\")\n",
    "# adjust rank functional issue ... \n",
    "state[\"moment1_u\"].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c92e948-ff3d-4007-8dae-8f9167c57722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 99]), torch.Size([10, 99]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[\"moment1_u\"].shape, state[\"moment1_v\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05be5de4-3afa-4785-8963-7751d6329790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.1801, -0.2629, -0.2272,  0.2899, -0.1162], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe245b3-4b02-4f0c-b4b1-ebf7811c93c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0571f8aa-38ff-4a53-8c50-e0840565017f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef89fb5d-7b67-4fea-94f5-ffd6bcebe361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3cee65-f092-4c59-b422-910dc95a63df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb0a23c-adc1-4a30-8d8d-80cbae02cb76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd728a54-8bfc-4b29-b621-fe4ac3565a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa2f32-4915-436c-b845-ff2801548034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6016874a-4172-4e76-9624-4c39e12a1d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "480100a9-eb63-452d-94ba-5d56cdd42abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of U: 5, 5 | V: 10, 5 | g: 5, 10\n",
      "Dtype of U: torch.float32 | V: torch.float32 | g: torch.float32\n",
      "Dtype of U Moment:  torch.float32\n",
      "Dtype of V Moment:  torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Debugging run for local_step \n",
    "\n",
    "from temp_yao import * \n",
    "self = yao_optimizer\n",
    "\n",
    "\n",
    "for group in self.param_groups:\n",
    "    lr = group[\"lr\"]\n",
    "    beta1, beta2 = group[\"adamw_betas\"]\n",
    "    eps = group[\"adamw_eps\"]\n",
    "    weight_decay = group[\"wd\"]\n",
    "    \n",
    "    # --- Low-Rank Params ---\n",
    "    lowrank_params = [p for p in group[\"params\"] if self.state[p][\"use_arg\"]]\n",
    "    for p in lowrank_params:\n",
    "        g = p.grad\n",
    "        if g is None:\n",
    "            continue\n",
    "    \n",
    "        state = self.state[p]\n",
    "        if \"step\" not in state:\n",
    "            # Initialize on first step\n",
    "            rank = min(g.shape)  # Default rank (adjust if needed)\n",
    "            state[\"step\"] = 0\n",
    "            state[\"moment1_u\"] = torch.zeros(g.shape[0], rank)\n",
    "            state[\"moment1_v\"] = torch.zeros(g.shape[1], rank)\n",
    "            state[\"moment1_s\"] = torch.zeros(rank)\n",
    "            state[\"moment2_s\"] = torch.zeros(rank)\n",
    "    \n",
    "        # Low-rank SVD approximation | this guy does not seem to support bfloat16 input type\n",
    "        U, S, V = svd_lowrank(g, q=state[\"moment1_u\"].shape[1], niter=2)\n",
    "    \n",
    "        print(f\"Shape of U: {to_shape(U)} | V: {to_shape(V)} | g: {to_shape(g)}\") \n",
    "        print(f\"Dtype of U: {U.dtype} | V: {V.dtype} | g: {g.dtype}\")\n",
    "    \n",
    "        print(\"Dtype of U Moment: \", state['moment1_u'].dtype)\n",
    "        print(\"Dtype of V Moment: \", state[\"moment1_v\"].dtype)\n",
    "        \n",
    "        # Update momentum buffers\n",
    "        state[\"step\"] += 1\n",
    "        \n",
    "        # _beta1 = torch.tensor(beta1, dtype=torch.bfloat16)\n",
    "        # _beta2 = torch.tensor(beta2, dtype=torch.bfloat16)\n",
    "    \n",
    "        state[\"moment1_u\"].lerp_(U, 1 - beta1)\n",
    "        state[\"moment1_v\"].lerp_(V, 1 - beta1)\n",
    "        state[\"moment1_s\"].lerp_(S, 1 - beta1)\n",
    "        state[\"moment2_s\"].lerp_(S.norm()**2, 1 - beta2)\n",
    "    \n",
    "        # Newton-Schulz orthogonalization\n",
    "        U = zeropower_via_newtonschulz5(state[\"moment1_u\"], group[\"ns_steps\"])\n",
    "        V = zeropower_via_newtonschulz5(state[\"moment1_v\"], group[\"ns_steps\"])\n",
    "        _mid = (state[\"moment1_s\"] / (eps + state[\"moment2_s\"].sqrt())).unsqueeze(-1).to(torch.bfloat16)\n",
    "        g = U @ (_mid * V.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
