{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2439d434-bd57-493a-a089-1b96f19ea722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "\n",
    "# model_dtype = torch.bfloat16 \n",
    "model_dtype = torch.float32\n",
    "\n",
    "model = nn.Linear(10, 5)\n",
    "model.to(model_dtype)\n",
    "\n",
    "# Toy case: \n",
    "# - multiplication operation (dimension pair multiply)\n",
    "N = 50\n",
    "input = torch.randn((N, 10)).to(model_dtype)\n",
    "output = input[:,::2] * input[:,1::2].to(model_dtype)\n",
    "\n",
    "def criterion(pred, target): \n",
    "    l2_loss = torch.norm(pred - output, p=2, dim=1)\n",
    "    return l2_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d81d14-76df-4f36-91ec-0b41002066e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from yao import YAO\n",
    "from temp_yao import YAO\n",
    "\n",
    "# yao optimizer\n",
    "yao_optimizer = YAO(params=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a6df97-16e8-47f0-a083-7a6ad6a4f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute loss \n",
    "pred = model(input)\n",
    "loss = criterion(pred, output)\n",
    "\n",
    "# Backward pass\n",
    "yao_optimizer.zero_grad()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d40cbc3-d2c2-47c5-8927-17926a6cd32d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# work for bfloat typed model parameters \n",
    "yao_optimizer._local_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad1d011-5329-467c-80fe-af5bebc71c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = U @ ((state[\"moment1_s\"] / (eps + state[\"moment2_s\"].sqrt())).unsqueeze(-1) * V.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c92e948-ff3d-4007-8dae-8f9167c57722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05be5de4-3afa-4785-8963-7751d6329790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6016874a-4172-4e76-9624-4c39e12a1d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "480100a9-eb63-452d-94ba-5d56cdd42abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of U: 5, 5 | V: 10, 5 | g: 5, 10\n",
      "Dtype of U: torch.float32 | V: torch.float32 | g: torch.float32\n",
      "Dtype of U Moment:  torch.float32\n",
      "Dtype of V Moment:  torch.float32\n"
     ]
    }
   ],
   "source": [
    "from temp_yao import * \n",
    "self = yao_optimizer\n",
    "\n",
    "\n",
    "for group in self.param_groups:\n",
    "    lr = group[\"lr\"]\n",
    "    beta1, beta2 = group[\"adamw_betas\"]\n",
    "    eps = group[\"adamw_eps\"]\n",
    "    weight_decay = group[\"wd\"]\n",
    "    \n",
    "    # --- Low-Rank Params ---\n",
    "    lowrank_params = [p for p in group[\"params\"] if self.state[p][\"use_arg\"]]\n",
    "    for p in lowrank_params:\n",
    "        g = p.grad\n",
    "        if g is None:\n",
    "            continue\n",
    "    \n",
    "        state = self.state[p]\n",
    "        if \"step\" not in state:\n",
    "            # Initialize on first step\n",
    "            rank = min(g.shape)  # Default rank (adjust if needed)\n",
    "            state[\"step\"] = 0\n",
    "            state[\"moment1_u\"] = torch.zeros(g.shape[0], rank)\n",
    "            state[\"moment1_v\"] = torch.zeros(g.shape[1], rank)\n",
    "            state[\"moment1_s\"] = torch.zeros(rank)\n",
    "            state[\"moment2_s\"] = torch.zeros(rank)\n",
    "    \n",
    "        # Low-rank SVD approximation | this guy does not seem to support bfloat16 input type\n",
    "        U, S, V = svd_lowrank(g, q=state[\"moment1_u\"].shape[1], niter=2)\n",
    "    \n",
    "        print(f\"Shape of U: {to_shape(U)} | V: {to_shape(V)} | g: {to_shape(g)}\") \n",
    "        print(f\"Dtype of U: {U.dtype} | V: {V.dtype} | g: {g.dtype}\")\n",
    "    \n",
    "        print(\"Dtype of U Moment: \", state['moment1_u'].dtype)\n",
    "        print(\"Dtype of V Moment: \", state[\"moment1_v\"].dtype)\n",
    "        \n",
    "        # Update momentum buffers\n",
    "        state[\"step\"] += 1\n",
    "        \n",
    "        # _beta1 = torch.tensor(beta1, dtype=torch.bfloat16)\n",
    "        # _beta2 = torch.tensor(beta2, dtype=torch.bfloat16)\n",
    "    \n",
    "        state[\"moment1_u\"].lerp_(U, 1 - beta1)\n",
    "        state[\"moment1_v\"].lerp_(V, 1 - beta1)\n",
    "        state[\"moment1_s\"].lerp_(S, 1 - beta1)\n",
    "        state[\"moment2_s\"].lerp_(S.norm()**2, 1 - beta2)\n",
    "    \n",
    "        # Newton-Schulz orthogonalization\n",
    "        U = zeropower_via_newtonschulz5(state[\"moment1_u\"], group[\"ns_steps\"])\n",
    "        V = zeropower_via_newtonschulz5(state[\"moment1_v\"], group[\"ns_steps\"])\n",
    "        _mid = (state[\"moment1_s\"] / (eps + state[\"moment2_s\"].sqrt())).unsqueeze(-1).to(torch.bfloat16)\n",
    "        g = U @ (_mid * V.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b633c682-cacd-40c7-accb-0eda43cb1ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.bfloat16, torch.bfloat16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.dtype, V.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60d6b6d3-6728-4348-aae1-dbc48ee4e4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix multiplication between: torch.bfloat16 and torch.float32\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected m1 and m2 to have the same dtype, but got: c10::BFloat16 != float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m prefix \u001b[38;5;241m=\u001b[39m U \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatrix multiplication between: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuffix\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m----> 4\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# prefix.to(torch.float32) @ suffix\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected m1 and m2 to have the same dtype, but got: c10::BFloat16 != float"
     ]
    }
   ],
   "source": [
    "suffix = (state[\"moment1_s\"] / (eps + state[\"moment2_s\"].sqrt())).unsqueeze(-1) * V.T\n",
    "prefix = U \n",
    "print(f\"Matrix multiplication between: {prefix.dtype} and {suffix.dtype}\") \n",
    "\n",
    "# Ok so it turns out matrix multiplication in pytorch can't be broadcasted ... (wow ...)\n",
    "torch.matmul(prefix, suffix)\n",
    "# prefix.to(torch.float32) @ suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73b45bcd-7ead-43fa-9552-5b134357b1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0195, -0.0508,  0.0397, -0.0012, -0.0154, -0.0679, -0.0075, -0.0488,\n",
       "         -0.0284,  0.0791],\n",
       "        [ 0.0272, -0.0519, -0.0193,  0.0081, -0.0672,  0.0202, -0.0529,  0.0829,\n",
       "         -0.0118,  0.0127],\n",
       "        [-0.0449, -0.0012,  0.0557, -0.0449, -0.0411,  0.0204,  0.0367,  0.0152,\n",
       "         -0.0749, -0.0259],\n",
       "        [-0.0453,  0.0112,  0.0470, -0.0059, -0.0011,  0.0357, -0.0406, -0.0013,\n",
       "          0.0434,  0.0357],\n",
       "        [ 0.0651,  0.0397,  0.0373,  0.0178, -0.0228,  0.0301,  0.0341,  0.0047,\n",
       "          0.0083,  0.0215]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(eps + state[\"moment2_s\"].sqrt()).unsqueeze(-1) * V.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dca452a-df71-4aad-8fcd-656641489410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31bb8242-3e7c-4c2d-8967-c486e4124956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = 1.0\n",
    "\n",
    "type(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f28b2a5e-8e04-4b3c-8a87-cbe9560a51cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of tensor g: torch.float32\n",
      "Data type after conversion for g: torch.bfloat16\n",
      "NS orthogonalization result dtype: torch.bfloat16\n",
      "Addition between torch.bfloat16 tensor and torch.bfloat16 tensor becomes: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "# Data Type Promoting experimentation ... \n",
    "\n",
    "import torch \n",
    "from moun import zeropower_via_newtonschulz5 as ns \n",
    "\n",
    "g = torch.rand(5, 10)\n",
    "print(f\"Data type of tensor g: {g.dtype}\") \n",
    "g = g.to(torch.bfloat16)\n",
    "print(f\"Data type after conversion for g: {g.dtype}\")\n",
    "x = ns(g, 2)\n",
    "print(f\"NS orthogonalization result dtype: {x.dtype}\")\n",
    "m = g \n",
    "m.add_(x, alpha=1.)\n",
    "print(f\"Addition between {m.dtype} tensor and {x.dtype} tensor becomes: {m.dtype}\")\n",
    "\n",
    "# Ok, so there are some addition-based broadcasting of tensor across dtype (indeed 'promotion of sort')\n",
    "# But why do I get the previous incompatibility issue if such broadcasting across dtype exists??\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15048a89-bee0-4eb5-9905-da990bcf85b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Testing wrapped randomized low-rank operator ::\n",
      "LowRank SVD on input: torch.float32\n",
      "- output type U : torch.float32 | S: torch.float32 | V: torch.float32 -\n",
      "LowRank SVD on input: torch.bfloat16\n",
      "- output type U : torch.bfloat16 | S: torch.bfloat16 | V: torch.bfloat16 -\n"
     ]
    }
   ],
   "source": [
    "from temp_yao import svd_lowrank # proudly presented functional\n",
    "\n",
    "print(\":: Testing wrapped randomized low-rank operator ::\")\n",
    "g = torch.rand(5,10)\n",
    "\n",
    "print(f\"LowRank SVD on input: {g.dtype}\")\n",
    "U, S, V = svd_lowrank(g, q=4, niter=2)\n",
    "print(f\"- output type U : {U.dtype} | S: {S.dtype} | V: {V.dtype} -\")\n",
    "\n",
    "g = g.to(torch.bfloat16)\n",
    "print(f\"LowRank SVD on input: {g.dtype}\")\n",
    "U, S, V = svd_lowrank(g, q=4, niter=2)\n",
    "print(f\"- output type U : {U.dtype} | S: {S.dtype} | V: {V.dtype} -\")\n",
    "\n",
    "g_approx = U @ (S.unsqueeze(-1) * V.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d8dde8b-838c-443c-b939-b77057c39dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Pytorch requires aligning dtype for matrix multiplication\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected m1 and m2 to have the same dtype, but got: float != c10::BFloat16",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m u \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m      7\u001b[0m v \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m8\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mbfloat16)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m \n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected m1 and m2 to have the same dtype, but got: float != c10::BFloat16"
     ]
    }
   ],
   "source": [
    "print(\":: Pytorch requires aligning dtype for matrix multiplication\")\n",
    "u = torch.randn(8, 4).to(torch.bfloat16)\n",
    "v = torch.randn(4, 8).to(torch.bfloat16)\n",
    "u @ v \n",
    "\n",
    "u = torch.randn(8, 4).to(torch.float32)\n",
    "v = torch.randn(4, 8).to(torch.bfloat16)\n",
    "u @ v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a642bc9-7e9e-4cb4-864b-2a3c958f1b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c80acfc-f886-4f6c-b57b-de1f15959c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.ones(5,10).to(\"cuda\")\n",
    "# U, S, V = torch.svd_lowrank(g, q=8, niter=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cd1dd2-7020-4c3a-94dc-59fe92bb9246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "218eb9ae-6aa8-4a92-a0a2-cf563653d45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2630, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define model (10 input features → 5 output features)\n",
    "model = nn.Linear(10, 5)\n",
    "\n",
    "# Toy case: Ensure output shape matches model's output (N, 5)\n",
    "N = 50\n",
    "input = torch.randn((N, 10))\n",
    "output = input[:, :5] * input[:, 5:]  # Shape (N, 5)\n",
    "\n",
    "def criterion(pred, target):\n",
    "    l2_loss = torch.norm(pred - target, p=2, dim=1)  # L2-norm per sample\n",
    "    return l2_loss.mean()\n",
    "\n",
    "# Optimizer (assuming YAO is imported)\n",
    "from yao import YAO\n",
    "yao_optimizer = YAO(params=model.parameters())\n",
    "\n",
    "# Forward pass\n",
    "pred = model(input)\n",
    "loss = criterion(pred, output)\n",
    "\n",
    "# Backward pass\n",
    "yao_optimizer.zero_grad()\n",
    "loss.backward()\n",
    "yao_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830ae121-211b-4c6c-a17a-e516b92fed6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
